{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774f91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of FICO → bucket → rating:\n",
      "   fico_score     fico_bucket  rating\n",
      "0         605  (587.0, 607.0]       8\n",
      "1         572  (560.0, 587.0]       9\n",
      "2         602  (587.0, 607.0]       8\n",
      "3         612  (607.0, 623.0]       7\n",
      "4         631  (623.0, 638.0]       6\n",
      "\n",
      "AUC: 0.709\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      2445\n",
      "           1       0.45      0.24      0.31       555\n",
      "\n",
      "    accuracy                           0.80      3000\n",
      "   macro avg       0.65      0.59      0.60      3000\n",
      "weighted avg       0.77      0.80      0.78      3000\n",
      "\n",
      "{'fico_score': 620, 'rating': np.int64(7), 'PD': 0.0545}\n",
      "{'fico_score': 680, 'rating': np.int64(3), 'PD': 0.0545}\n",
      "{'fico_score': 720, 'rating': np.int64(1), 'PD': 0.0545}\n",
      "{'fico_score': 780, 'rating': np.int64(1), 'PD': 0.0545}\n",
      "{'fico_score': 820, 'rating': np.int64(1), 'PD': 0.0545}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# =========================================\n",
    "# 1. Load data\n",
    "# =========================================\n",
    "\n",
    "df = pd.read_csv(r\"C:/Users/athil/JPM quantitative research/Task3/Task 3 and 4_Loan_Data.csv\")\n",
    "\n",
    "# Make sure these column names match your file:\n",
    "fico_col = \"fico_score\"\n",
    "target_col = \"default\"\n",
    "\n",
    "fico = df[fico_col].values\n",
    "y = df[target_col].values.astype(int)\n",
    "\n",
    "# =========================================\n",
    "# 2. Create fast FICO buckets using quantiles\n",
    "# =========================================\n",
    "\n",
    "N_BUCKETS = 10   # you can change to 5, 7, etc.\n",
    "\n",
    "# qcut will create ~equal-sized buckets in terms of number of rows\n",
    "# retbins=True gives us the bin edges so we can reuse them later\n",
    "df[\"fico_bucket\"], bins = pd.qcut(\n",
    "    df[fico_col],\n",
    "    q=N_BUCKETS,\n",
    "    retbins=True,\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "# buckets are categorical intervals like (650.0, 680.0]\n",
    "# convert them into ordered integer ratings\n",
    "\n",
    "# First, get codes 0..K-1 in ascending FICO order\n",
    "df[\"bucket_code\"] = df[\"fico_bucket\"].cat.codes   # 0 = lowest FICO bucket\n",
    "\n",
    "# We want rating 1 = BEST (highest FICO)\n",
    "# So invert: rating = K - code\n",
    "K = df[\"bucket_code\"].max() + 1\n",
    "df[\"rating\"] = K - df[\"bucket_code\"]\n",
    "\n",
    "print(\"Sample of FICO → bucket → rating:\")\n",
    "print(df[[fico_col, \"fico_bucket\", \"rating\"]].head())\n",
    "\n",
    "# =========================================\n",
    "# 3. Train PD model on rating (categorical)\n",
    "# =========================================\n",
    "\n",
    "# One-hot encode rating for logistic regression\n",
    "X = pd.get_dummies(df[\"rating\"].astype(\"category\"),\n",
    "                   prefix=\"rating\",\n",
    "                   drop_first=True)\n",
    "\n",
    "feature_cols = X.columns  # save for later\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# =========================================\n",
    "# 4. Evaluate the model\n",
    "# =========================================\n",
    "\n",
    "y_proba = logit.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"\\nAUC:\", round(auc, 3))\n",
    "\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, (y_proba > 0.5).astype(int)))\n",
    "\n",
    "# =========================================\n",
    "# 5. Helper: map new FICO → rating, using the same bins\n",
    "# =========================================\n",
    "\n",
    "def map_fico_to_rating_quick(score, bins):\n",
    "    \"\"\"\n",
    "    score : numeric fico score\n",
    "    bins  : array of bin edges from qcut\n",
    "\n",
    "    Returns rating where 1 = best, K = worst.\n",
    "    \"\"\"\n",
    "    # np.digitize gives bin index 1..len(bins)-1\n",
    "    code = np.digitize(score, bins[1:-1], right=True)  # 0..K-1\n",
    "    K = len(bins) - 1\n",
    "    rating = K - code\n",
    "    return rating\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 6. Predict PD for a new FICO score\n",
    "# =========================================\n",
    "\n",
    "def predict_pd_for_new_fico(fico_score, bins, model, feature_cols):\n",
    "    \"\"\"\n",
    "    Given a new FICO score, map it to rating and compute PD.\n",
    "    \"\"\"\n",
    "    rating = map_fico_to_rating_quick(fico_score, bins)\n",
    "\n",
    "    tmp = pd.DataFrame({\"rating\": [rating]})\n",
    "    X_new = pd.get_dummies(tmp[\"rating\"].astype(\"category\"),\n",
    "                           prefix=\"rating\",\n",
    "                           drop_first=True)\n",
    "\n",
    "    # align with training columns\n",
    "    X_new = X_new.reindex(columns=feature_cols, fill_value=0)\n",
    "\n",
    "    pd_val = float(model.predict_proba(X_new)[0, 1])\n",
    "\n",
    "    return {\n",
    "        \"fico_score\": fico_score,\n",
    "        \"rating\": rating,\n",
    "        \"PD\": round(pd_val, 4)\n",
    "    }\n",
    "\n",
    "# =========================================\n",
    "# 7. Example predictions\n",
    "# =========================================\n",
    "\n",
    "for s in [620, 680, 720, 780, 820]:\n",
    "    print(predict_pd_for_new_fico(s, bins, logit, feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f110311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fico_score  rating  PD_estimated\n",
      "0         605       8      0.242023\n",
      "1         572       9      0.313827\n",
      "2         602       8      0.242023\n",
      "3         612       7      0.168794\n",
      "4         631       6      0.168713\n"
     ]
    }
   ],
   "source": [
    "#add PD for all rows in the dataset\n",
    "# X is the full feature matrix for all rows (built earlier from df[\"rating\"])\n",
    "# feature_cols = X.columns\n",
    "\n",
    "# 1) Predict PD for every row in the dataset\n",
    "df[\"PD_estimated\"] = logit.predict_proba(X)[:, 1]\n",
    "\n",
    "# 2) Optional: check a few rows\n",
    "print(df[[\"fico_score\", \"rating\", \"PD_estimated\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new CSV\n",
    "df.to_csv(\"mortgage_with_PD.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected Loss for each row\n",
    "LGD = 0.9  \n",
    "EAD_col = \"loan_amt_outstanding\"  \n",
    "\n",
    "df[\"Expected_Loss\"] = df[\"PD_estimated\"] * df[EAD_col] * LGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Expected Loss for mortgage portfolio: 6982996.29\n"
     ]
    }
   ],
   "source": [
    "#Total Expected Loss \n",
    "total_EL = df[\"Expected_Loss\"].sum()\n",
    "print(\"Total Expected Loss\", round(total_EL, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the exact dynamic-programming optimization of the quantization boundaries\n",
    "#  is computationally heavy for large loan portfolios, \n",
    "# I adopted a fast quantile-based bucketing strategy. \n",
    "# FICO scores are split into K buckets with roughly equal populations using qcut,\n",
    "#  then mapped to ordinal ratings where rating 1 represents the best credit quality.\n",
    "#  These ratings are one-hot encoded and used as categorical inputs \n",
    "# to a logistic regression PD model.”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
